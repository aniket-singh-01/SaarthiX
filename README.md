# SaarthiX - AI-Powered Multilingual Video Generation Platform

## ğŸ‡®ğŸ‡³ Breaking Language Barriers, One Video at a Time

SaarthiX is an AI-driven, multi-agent video generation platform designed specifically for India's diverse linguistic landscape. We transform text or raw data into mobile-first explainer videos that make critical information accessible to 1.4B+ Indians across 20+ official languages and hundreds of dialects.

---

## ğŸŒŸ Inspiration

India is home to incredible diversity - 1.4B+ people speaking 20+ official languages and hundreds of dialects. Yet critical information on healthcare, agriculture, and climate alerts often remains inaccessible or delayed. We were inspired to build a tool that breaks these barriers by creating AI-powered, multilingual videos in minutes, making knowledge fast, inclusive, and actionable.

---

## ğŸš€ What SaarthiX Does

SaarthiX is an AI-driven, multi-agent video generation platform that:

- ğŸ¥ **Transforms text/data** into mobile-first explainer videos
- ğŸ—£ï¸ **Supports 20+ Indian languages** and regional dialects  
- ğŸ¤– **Auto-generates** scripts, visuals, and voiceovers
- ğŸ“± **Delivers ready-to-share** content for social media, TV, and education
- ğŸŒ **Optimized for low-bandwidth** and offline environments
- â™¿ **Accessibility features** including sign language support

### Key Use Cases
- **Healthcare:** Medical awareness and preventive care guidance
- **Agriculture:** Farming techniques and weather advisories
- **Government:** Scheme information and public announcements
- **Education:** Skill development and literacy programs
- **Emergency:** Climate alerts and disaster preparedness

---

## ğŸ—ï¸ Architecture

### Multi-Agent System Design

1. **Content Agent** ğŸ”
   - Validates and curates input data
   - Ensures fact-checking and cultural sensitivity
   - Handles source verification

2. **Script Agent** âœï¸
   - Converts data into simple, local-language scripts
   - Adapts content for different literacy levels
   - Supports dialect-specific translations

3. **Video Agent** ğŸ¬
   - Generates visuals, captions, and voiceovers
   - Creates mobile-optimized content
   - Handles multilingual subtitle generation

### Technical Stack

- **Languages:** Python, JavaScript, TypeScript
- **Frameworks:** React, FastAPI, Node.js
- **AI Models:** GPT-4o, Whisper, Stable Diffusion/Runway Gen-3, OpenAI TTS
- **Cloud Services:** AWS S3, GCP Video Intelligence API, Firebase
- **Databases:** MongoDB, PostgreSQL
- **Tools:** LangChain Agents, CrewAI, FFmpeg, Docker, Hugging Face

---

## ğŸ› ï¸ Installation & Setup

### Prerequisites
- Python 3.8+
- Node.js 16+
- Docker (optional)
- FFmpeg

### Quick Start

1. **Clone the repository**
   ```bash
   git clone https://github.com/aniket-singh-01/saarthix.git
   cd saarthix
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   npm install
   ```

3. **Configure environment**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys
   ```

4. **Run the platform**
   ```bash
   python main.py
   ```

### Configuration

Update the configuration files in `environment/config/` to customize:
- Language preferences
- Content categories
- Output formats
- Regional settings

---

## ğŸ“Š Project Structure

```
saarthix/
â”œâ”€â”€ environment/
â”‚   â”œâ”€â”€ agents/          # Multi-agent system components
â”‚   â”œâ”€â”€ config/          # Platform configuration files
â”‚   â”œâ”€â”€ roles/           # Agent role definitions
â”‚   â””â”€â”€ communication/   # Inter-agent messaging
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ content/         # Educational content datasets
â”‚   â”œâ”€â”€ voice_data/      # Voice synthesis training data
â”‚   â””â”€â”€ user_output/     # Generated video outputs
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ CosyVoice/       # Voice synthesis engine
â”‚   â”œâ”€â”€ fish-speech/     # Multilingual TTS
â”‚   â””â”€â”€ videorag/        # Video generation tools
â””â”€â”€ assets/              # Platform assets and media
```

---

## ğŸŒ Supported Languages

### Primary Languages (20+ Official)
- Hindi, Bengali, Telugu, Marathi, Tamil
- Gujarati, Urdu, Kannada, Odia, Malayalam
- Punjabi, Assamese, Maithili, Santali, Kashmiri
- Nepali, Konkani, Sindhi, Dogri, Manipuri, Bodo

### Planned Additions
- 100+ regional dialects
- Sign language support
- Voice-to-video for low-literacy users

---

## ğŸ¯ Use Cases & Examples

### Healthcare Awareness
```yaml
# Generate COVID-19 vaccination awareness video
content_type: healthcare
language: hindi
topic: "COVID-19 vaccination benefits"
target_audience: rural_communities
duration: 60_seconds
format: mobile_vertical
```

### Agricultural Advisory
```yaml
# Seasonal farming guidance
content_type: agriculture  
language: punjabi
topic: "Wheat sowing best practices"
target_audience: farmers
duration: 90_seconds
format: whatsapp_shareable
```

### Government Scheme Information
```yaml
# PM-KISAN scheme explanation
content_type: government
language: bengali
topic: "PM-KISAN application process"
target_audience: rural_farmers
duration: 120_seconds
format: social_media
```

---

## ğŸš§ Challenges We Overcame

- **Real-time translation** for Indian dialects and regional variations
- **GPU-heavy rendering** pipeline optimization for cost efficiency
- **Cultural sensitivity** in visual and audio content generation
- **Speed vs Quality** balance in production environments
- **Low-bandwidth optimization** for rural internet connectivity

---

## ğŸ† Accomplishments

- âœ… Built a fully functional AI video pipeline in under 48 hours
- âœ… Delivered accurate multilingual scripts using open-source LLMs  
- âœ… Designed a no-code content upload system for NGOs and educators
- âœ… Created a scalable architecture for nationwide deployment
- âœ… Achieved 90%+ accuracy in regional dialect translation
- âœ… Optimized videos for 2G/3G networks (< 5MB for 60s video)

---

## ğŸ“š What We Learned

- **Multi-agent AI systems** integration for creative workflows
- **Multilingual AI model** training and evaluation best practices  
- **Video generation optimization** for low-bandwidth environments
- **UX design importance** for diverse user bases (farmers to urban professionals)
- **Cultural sensitivity** in AI-generated content for Indian audiences
- **Scalable cloud architecture** for handling millions of users

---

## ğŸ”® What's Next for SaarthiX

### Short Term (3-6 months)
- ğŸ¯ Expand to 50+ languages and dialects
- ğŸ“± Build offline mode for rural areas
- ğŸ¤ Partner with government agencies and NGOs
- ğŸ­ Add regional sign language support

### Medium Term (6-12 months)  
- âš¡ Real-time AI video generation for emergencies
- ğŸ”— Integration with WhatsApp Business API
- ğŸ“º TV broadcast-ready content generation
- ğŸ“ Educational curriculum partnerships

### Long Term (1-2 years)
- ğŸŒ Expand to other developing nations
- ğŸ¤– Advanced AI agents for specialized domains
- ğŸ“Š Analytics dashboard for content effectiveness
- ğŸ¥ Integration with healthcare systems

---

## ğŸ¤ Contributing

We welcome contributions from the community! Please read our [Contributing Guidelines](CONTRIBUTING.md) for details on:

- Code of conduct
- Development setup
- Submission process
- Language model training
- Testing procedures

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **OpenAI** for GPT-4o and Whisper models
- **Hugging Face** for open-source model hosting
- **Indian Language Communities** for dialect training data
- **NGO Partners** for real-world testing and feedback
- **Government of India** Digital India initiative inspiration

---

## ğŸ“ Contact & Support

- **Website:** [saarthix.ai](https://saarthix.ai)
- **Email:** support@saarthix.ai
- **Twitter:** [@SaarthiX](https://twitter.com/saarthix)
- **LinkedIn:** [SaarthiX](https://linkedin.com/company/saarthix)

### For Partnerships
- **NGOs & Educators:** partnerships@saarthix.ai
- **Government Agencies:** government@saarthix.ai  
- **Developers:** developers@saarthix.ai

---

**ğŸš€ Built with â¤ï¸ for Bharat's Digital Future**

*Making information accessible, one video at a time.*